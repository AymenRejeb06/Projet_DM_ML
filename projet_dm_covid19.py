# -*- coding: utf-8 -*-
"""Projet DM covid19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wzdfezHAnAEXLYeRVgI6-YRqyQEOyJ8a
"""

import pandas as pd
from matplotlib import pyplot as pit
import numpy as np
from sklearn.model_selection import train_test_split
import seaborn as sn
dataset_Train = pd.read_csv("Coronavirus_Tunisia.csv")

pd.options.display.max_colwidth = 200

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import accuracy_score

data= pd.read_csv("Coronavirus_Tunisia.csv")
data.info

data

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
pd.options.display.max_colwidth = 400 
figure(num=None, figsize=(10, 10))
plt.hist(dataset_Train['city'])
plt.xlabel('city')
plt.ylabel('case')

stable = dataset_Train[dataset_Train['age']<60]['case'].value_counts() 
danger  = dataset_Train[dataset_Train['age']>60]['case'].value_counts()

danger

city = pd.DataFrame([stable, danger])
city.index = ['stable', 'danger']
city.plot(kind = 'bar', stacked = True, figsize = (10,10))

dataset_Train.head()

dataset_Train.isna().sum()

dataset_Train.max()

dataset_Train['case'] = dataset_Train['case']/89
dataset_Train['age'] = dataset_Train['age']/83

dummies = ['case' , 'confirmation_date','age', 'gender', 'city', 'symptomatic', 'return_from', 'country']

dataset_Train.dtypes

dataset_Train['case'].dropna()

dataset_Train.case = dataset_Train['case'].map({'danger': 1, 'stable': 0})

dataset_Train.head()

X=dataset_Train.loc[:, dataset_Train.columns != 'case']
y=dataset_Train.iloc[:,0]

X.head()

from sklearn import tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn import preprocessing 
from sklearn import metrics
from sklearn.metrics import confusion_matrix,accuracy_score

X_train,y_train,=(X,y,test_size=0.3,random_state=10)

clf = tree.DecisionTreeClassifier()
clf = clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

accuracy = accuracy_score(y_test,y_pred)

accuracy

import pickle
pickle.dump(clf, open("model_tree.pkl",'wb'))

model = pickle.load(open("model_tree.pkl",'rb'))

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

k_fold = KFold(n_splits = 10, shuffle = True, random_state  =0)

tree = tree.DecisionTreeClassifier()
scoring = 'accuracy'
score = cross_val_score(tree, X, y, cv= k_fold, n_jobs=1, scoring=scoring)
print(score)

forest = RandomForestClassifier()
scoring = 'accuracy'
score = cross_val_score(forest, X, y, cv= k_fold, scoring=scoring)
print(score)

(np.mean(score))

k_scores = []
for i in range(10,50) :   
    knn = KNeighborsClassifier(n_neighbors = i)
    scoring = 'accuracy'
    score = cross_val_score(knn, X, y, cv = k_fold, scoring = scoring)  
    k_scores.append(np.mean(score))
print(k_scores)

k_range = range(10, 50)
plt.plot(k_range, k_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-Validated Accuracy')

knn_best = KNeighborsClassifier(n_neighbors = 35)

scoring = 'accuracy'

score = cross_val_score(knn_best, X, y, cv = k_fold, n_jobs = 1, scoring = scoring)

print(score)

(np.mean(score))

